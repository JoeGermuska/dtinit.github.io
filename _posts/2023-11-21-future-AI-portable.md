---
title: The future of generative AI is personal – and portable?
tags: trust
author: Chris Riley
excerpt: Generative AI news fills all inboxes. But a key question of its future isn't yet being asked: will users be locked in, or will their data be portable?
---

We’ve had lots of tech policy bubbles in recent years, issues that dominated the headlines for a time, then faded away as the promises of an emerging technology were revealed as more illusional than illustrious. Today, public attention (and massive investment) is intensely focused on the power of large language models to create compelling artificial language and imagery.

The list of luminaries citing generative AI’s awesomeness is long; I’ll stick with just one: [Bill Gates](https://www.gatesnotes.com/The-Age-of-AI-Has-Begun?WT.mc_id=20231109150000_AI-Agents_BG-Thr_&WT.tsrc=BGThr&utm_source=pocket_reader) calls it the most revolutionary technology he has seen since the graphical user interface in 1980. In [my own writing](https://techpolicy.press/past-present-future-ai-geopolitics-and-the-global-economy/), I’ve tried to contextualize some of the technology’s potential. But, without question, the future will be different as a result of advancements in the ability of large language models to produce creative output that can (in some contexts and circumstances) pass for human-made.

The future of generative AI itself is far from determined, as it sits on shifting sands of corporate investment, innovation, and governance. One existential question gets substantial airplay: whether AI will somehow break beyond human containment. But a more proximate question looms behind the scenes, one that isn’t being asked: whether the future of generative AI will lock users into new technology silos, or empower them by ensuring portability.

## From new to widespread

The shine of generative AI will likely come off a bit as the costs and limitations of its high computational tasks become more widely felt. And it’s unclear just how much these systems can actually replace humans in professional creative tasks. But at minimum, generative AI tools will have a durable place as agents supporting human research and development in various ways.

There are many open questions regarding the future of these tools, and the role of regulation is a big one. The U.S. White House has released a [sweeping, forward-looking executive order](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/) (which is being [fairly](https://mashable.com/article/openai-response-ai-executive-order-silence#:~:text=The%20Biden%2DHarris%20administration's%20far,development%20of%20its%20AI%20tools.) [well](https://www.msn.com/en-gb/money/other/ai-executive-order-is-a-historic-moment-credo-ceo-singh/vi-AA1jaxSr) [received](https://publicknowledge.org/public-knowledge-applauds-white-house-executive-order-to-safeguard-ai-development/)) to do its part to invest in foundational safety improvements, particularly in the void of Congressional inaction. The European Union’s landmark AI Act, long poised to be a worldwide leader, [has been derailed](https://www.euractiv.com/section/artificial-intelligence/news/eus-ai-act-negotiations-hit-the-brakes-over-foundation-models/) by the issue of how to handle foundational models; the EU has another chance in December to pull it together and pass a law, but that outcome at this point is not certain.

One piece feels missing from these conversations, a piece made much more clear by the shift towards personalized experiences. It’s the role of user switching and portability in the market for generative AI. Will we be stuck in the future using a specific company’s AI product because of the time and effort we’ve invested in tailoring it to our preferences, or will we be able to take the data reflecting that work and move it somewhere else?

The generative AI field is expansive already and continuing to expand. To view it as a single market would be an oversimplification. Nevertheless, with the scale of investment and the number of very large players in this space, it seems inevitable that with any interesting and valuable generative AI use case, alternative and substitutable services will emerge. It also seems virtually certain that growth and value among nascent competitors will focus not just on the size of the model as a general-purpose tool, but on its capability for being personal.

## From widespread to personal

Increasingly, generative AI tools are personal tools. One trend in this direction is the exploration of [on-device generative AI](https://www.axios.com/newsletters/axios-ai-plus-b5dec4be-0efa-41c5-b2e5-b2e747846c56.html?chunk=0#story0), systems that can run locally without dependency on cloud infrastructure. Another, very visible dimension is the shift towards [custom GPT tools](https://www.theverge.com/2023/11/6/23948957/openai-chatgpt-gpt-custom-developer-platform) – instances of a broader foundation model adapted to specific desired styles of engagement and additional knowledge bases to draw from beyond core training data.

The market is shifting quickly from commodity generative technologies toward one where it’s not only the raw power of the large language model that matters, but also its ability to tailor itself over time in response to your input. In other words, like the rest of the internet, AI becomes more valuable through user data – and thus poses an increasing risk of lock-in effects.

As the future of generative AI becomes more personal, it’s not too soon to push for that future to also be portable.

## From personal to portable

Imagine an artist who has built a custom art generation AI agent. She has provided to the agent extensive guidance, limits, technical preferences like size of image and detail, and countless ineffable aesthetic preferences, tweaking steadily over weeks and months of use. What happens if she wants, or needs, to try a different AI service provider? Will she be able to download her customizations and interactions that developed the agent’s particular style? And even if she can download them, will the AI engine she wants to try out be able to make any sense of them?

For any new audiences this message may be reaching (familiar audiences, feel free to skip to the next paragraph!): This problem is at the core of our mission at the Data Transfer Initiative. The open-source [Data Transfer Project](https://dtinit.org/assets/dtp-overview.pdf) was established several years ago to catalyze a movement to build tools to help users move their personal data online. At DTI, we’ve assumed stewardship of this project and the mantle of a champion to build a healthy ecosystem for user data transfers. We’ve articulated [core principles](https://dtinit.org/assets/dti-onepager.pdf) to guide the policy and technical challenges that arise along that journey.

At the moment, the baseline of openness in the generative AI ecosystem is fairly high. For example, users of OpenAI’s ChatGPT can download both their prompts to the service and its responses; and their [custom GPTs](https://openai.com/blog/introducing-gpts) open the door for downstream innovation with the potential of significant mutual benefit. [Google Takeout](https://takeout.google.com/) includes Bard data in its “My Activity” download options. And there is substantial investment in open source models as well, including [Meta’s Llama](https://ai.meta.com/llama/). (Though there is considerable debate about the criteria under which a model is truly open source.)

But openness and effective portability aren’t the same thing. And even if today’s openness continues and grows, more work will be needed to ensure a portable generative AI future.

## From portable to empowered

Between a good baseline of openness and the relative novelty of personalized AI, portability may not yet be front of mind, but will soon become a pressing concern. With so much public attention on competition in the tech sector, and an increased awareness of data portability as a positive direction for pro-competitive investment, it is time to lay the groundwork.

The same questions that motivated the Digital Markets Act in its shift from traditional reactive, antitrust concepts towards proactive obligations for designated gatekeepers apply here. Generative AI services similarly have the potential to lock in users, although it is not inevitable.

There are many open questions within a goal of portable generative AI, such as the nature and types of data needed for effective migration, and questions of purpose and proprietary interests. A lot of work lies ahead.

But over the long term, the right answer is to empower people to be stakeholders in shaping the future of the generative AI space, in principal part by allowing them to transfer their data.
