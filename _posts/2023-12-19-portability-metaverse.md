---
title: Data Portability and the Metaverse – Q&A with Joe Jerome
tags: metaverse
author: Delara Derakhshani
excerpt: "DTI's Director of Policy Delara interviews Joe Jerome in advance of DTI's future event showcasing Joe and other scholars writing on portability."
thumbnail: /images/blog/Firefly-Train-Schedule.jpg
---

At DTI, we’re working at the cutting edge of data portability. One of the most exciting parts of my job as Director of Policy is pushing the frontiers of data knowledge with experts in the field, including people working on emerging technologies.

For this edition of DTI’s newsletter, I am pleased to interview Joseph Jerome, Visiting Assistant Professor, University of Tampa and a leading voice in AR/VR policy. Joe and I worked together for several years at Meta and I got to know him as one of the leading experts on privacy and data policy in emerging technologies. I’m excited to discuss with him some of the challenges and unique opportunities for value creation in the Metaverse.

We look forward to exploring these and other issues in more depth with Joe and other scholars at our upcoming event on February 29, which will bring together academics, civil society, regulators, and industry for a day of in-depth discussion about the future of data portability.

–---------

**DD: How does data portability fit into the “Metaverse” and its core principles?**

JJ: There are a couple of major definitional challenges that need to be addressed before we even get to data portability. First, the Metaverse as it’s often fully imagined does not currently exist. We’re building toward a future vision that often means very different things to different companies. We have massive multiplayer experiences like Fortnite and mass market virtual reality headsets, but augmented reality is still largely limited to what’s doable on mobile and a sort of shared AR experience doesn’t exist – no disrespect to Niantic. 

I’m not sure anyone’s agreed on a set of core principles for the Metaverse, but I think everyone believes that interoperability among different parts of the tech stack will be important for an immersive internet to meet its full potential. Meta’s initial tagline for the Metaverse was that it should be open and interoperable, and I think a lot of the coolest use cases that people have dreamed up for immersive technologies are going to require different companies’ apps and services to seamlessly work together. 

Like many, Mark Zuckerberg has defined the Metaverse as an “embodied internet.” An internet that is overlaid on our real physical environment and full of interactive avatars based on real life people is qualitatively different from the sorts of user-generated content that define web2.0. 

**DD: What do you see has the potential for data portability in this new space, in light of some of these qualitative differences?**

JJ: Data portability has a lot of interesting potential where new AR/VR data types are concerned. Now, I’m not optimistic that Meta’s mixed reality experiences are going to work alongside Apple’s vision for augmented reality in the near-to-medium term, but that shouldn’t stop us from looking at some form of useful data portability as a good first step. 

If this is the next iteration of the internet, it’s also an opportunity to try to do portability better than we have before. Let’s find ways to make it easier for users to create avatars and port their content or let developers build and index spatial maps.

**DD: What types of data do you think data portability stakeholders should focus on in this new space?**

JJ: To be clear, a clear taxonomy of data that make up the Metaverse does not exist. At the same time, much of the data generated by immersive technologies and virtual worlds is likely not much different to what is already common on social media, other multiuser online experiences, or any device with a bunch of sensors on it. Digital entitlements are – or perhaps were – also envisioned as an important component of a web3.0/Metaverse vision. 

User-generated content has been the killer app of social media, but the portability tools we’ve created for social media have largely extended to text and 2D images. The UGC that powers social experiences like Roblox and Second Life is three dimensional and fully interactive. We’re going to see much more of that in the Metaverse. 

For instance, Meta has [announced a plan](https://www.uploadvr.com/quest-3-augments/) to launch mixed reality “augments” in 2024. These are spatially-aware virtual objects that are persistently anchored to a person’s physical space. Imagine the ability to create and place a virtual object of anything, anywhere, and have it react uniquely to individuals that come across it. The potential is limitless, and although it’s probably going to be a while before users can port their virtual pets from platform to platform, what about their virtual whiteboards, pop-up notes, or warning signs?

Immersive technologies also generate some data that strike me as net new. First, biometric or biometrically-adjacent data has already received a lot of attention for its significant privacy implications, but this sort of body data will be important to personalize immersive experiences. Lots of companies have been very bullish about building technologies to let users create avatars of varying degrees of realism and fidelity. I would like to see companies explore how data portability might work for digital avatars. Right now, I have separate Bitmoji, Apple Memoji, Nintendo Mii, and, yes, even a Meta avatar or two. Each of these stylized avatars looks generally the same, and yet I’ve been forced into one content creator after another just to select a bald option with glasses and brown eyes. Why can’t the data that make up a basic stylized avatar be exportable and shareable across services? 

Another type of data that gets far less attention is spatial mapping information. In order to realistically place virtual objects in physical space, devices need to be able to understand their physical surroundings. This requires different mapping layers. There are all sorts of conversations about spatial mapping occurring at the Metaverse Standards Forum, and industry stakeholders are exploring both open and closed approaches to building and sharing spatial maps, with the “Overture Maps Foundation” effort within the Linux Foundation led by Amazon, Meta, and Microsoft as a potential counterweight to Google Maps.

Spatial maps will ultimately be leveraged to allow individuals to populate the real world with virtual objects of their own creation. My hope is that we can avoid the sorts of persistent lock-in challenges that have bedeviled social media when it comes to the virtual art I place on my walls and share with my friends and family.

**DD: This sounds like an enormous amount of data. Who’s going to benefit from it? Who’s going to see the most use or value from this data?**

JJ: Everyone recognizes sensor technologies collect more data than ever and building an embodied, immersive internet is going to require huge amounts of data, but it’s not clear what data in this ecosystem is valuable and to whom. 

Furthermore, I am not sure average people care about data portability for data portability’s sake. Data portability is only important to the extent that it allows individuals to do cool things, efficiently, with the device or service of their choosing. 

**DD: An apt observation and a frequent topic of discussion at DTI. As our Executive Director Chris Riley [has pointed out](https://dtinit.org/blog/2023/07/01/measure-the-value), there are challenges to unlocking the full value of user data. And then there’s the question of how to quantify the value of data in the first place.**

JJ: Right. And this is important because we need to think about useful data portability as not merely a user benefit but as something that might spur competition and innovation among AR/VR developers.

**DD: What are some external constraints before this becomes a reality?**

JJ: If we’re being honest, it is not clear what incentive the major players in this ecosystem have to prioritize portability or if immersive technology platforms are giving much thought to it. But even if they are, the vision for data portability has to extend beyond being a regulatory requirement stemming from privacy laws. 

If regulation means hard law, the data being generated by immersive technologies will be governed by the vast array of global privacy laws that already exist. It’s likely that newer proposals that address some of the challenges posed by artificial intelligence will capture exciting Metaverse-adjacent use cases. I personally am very interested to see how stakeholders view the EU Data Act, which I read as providing a strong mandate for additional data portability captured by AR/VR devices. 

But regulation can also mean standards setting. The Metaverse Standards Forum has been a hotbed of activity there, and one effort that the MSF agreed to early on was to document an inventory of Metaverse-related standards. I am excited to see what DTI could do in this space someday!

The big issue is that data portability is now often talked about as one of a bundle of privacy rights. Rights to portability of some forms of personal data appeared in the GDPR and have been embraced in the United States, but portability fits awkwardly with other privacy rights. 

It also means that portability now gets discussed as a regulatory requirement that emerges from how companies operationalize individual privacy rights. This is a problem because it ensures that platforms won’t build portability solutions that work for developers and competitors. Legal requirements like the EU Data Act might push companies to do better, but that may require policymakers to make clearer asks of companies up and down the tech stack to make more data portable in a useful fashion.  

**DD: Yeah. This complex fit with individual privacy is one of the reasons we’re so focused on a different law, the EU’s Digital Markets Act, which has portability tied more to competition goals. It’ll be interesting to see how metaverse portability – and interoperability – continue to develop in the post-DMA world, alongside the technologies and platforms themselves, and their use cases.**
